// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`basic completion 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "wallwallwallwallwallwallwallwallwallwall",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`basic completion: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "llama ?B Q4_0",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 512,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`completion with response_format: json_object 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{}
		              			<|eot_id|>",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 4,
  "tokens_predicted": 4,
  "truncated": false,
}
`;

exports[`completion with response_format: json_schema 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{
 				 				 				 				",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 13,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with tools 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{
	   	   	   	   	   "tool_ca",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 270,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`embedding: Embedding (normalized) 1`] = `
[
  -0.02556,
  -0.01892,
  0.04267,
  -0.0394,
  0.02378,
  0.01411,
  0.03276,
  -0.00064,
  0.0449,
  -0.00375,
  -0.01076,
  0.0277,
  0.02833,
  0.0233,
  0.0318,
  -0.01599,
  -0.0257,
  -0.04135,
  -0.12206,
  -0.00438,
  0.07839,
  -0.08026,
  0.02326,
  0.03116,
  0.01228,
  0.01604,
  0.00967,
  -0.04327,
  -0.03623,
  -0.09784,
  -0.00982,
  -0.04233,
  0.03412,
  -0.00953,
  0.00546,
  0.07445,
  -0.02441,
  0.04472,
  -0.00548,
  -0.01955,
  0.00289,
  -0.01395,
  -0.05628,
  -0.05358,
  -0.08858,
  -0.03358,
  -0.02183,
  0.00962,
  0.03647,
  0.01961,
  -0.00747,
  -0.04001,
  0.05229,
  -0.01646,
  -0.02041,
  0.05197,
  0.05672,
  -0.01152,
  0.02973,
  -0.00274,
  0.03046,
  0.01868,
  -0.13459,
  0.08557,
  0.08866,
  0.027,
  0.03041,
  -0.03951,
  0.0309,
  -0.02549,
  -0.09914,
  0.0041,
  0.04517,
  0.02459,
  0.01875,
  0.09959,
  0.00259,
  -0.03366,
  0.0009,
  -0.02744,
  -0.00084,
  0.00499,
  -0.02024,
  0.04731,
  0.05027,
  -0.0049,
  -0.00964,
  -0.03545,
  0.07092,
  -0.01317,
  -0.06413,
  -0.01285,
  -0.00691,
  0.04852,
  -0.08234,
  -0.02903,
  0.07336,
  -0.05784,
  0.03574,
  0.32592,
  -0.09732,
  0.03691,
  0.04529,
  0.03393,
  0.04075,
  -0.03373,
  0.05759,
  -0.07919,
  0.06926,
  0.012,
  0.01382,
  -0.09025,
  -0.01861,
  -0.07984,
  -0.009,
  0.06823,
  0.04607,
  -0.00644,
  0.01853,
  0.03258,
  0.01529,
  0.03086,
  -0.03176,
  -0.05726,
  -0.07664,
  -0.06625,
  0.11834,
  0.05571,
  -0.02049,
  -0.04106,
  0.03106,
  -0.01331,
  0.00604,
  0.01695,
  -0.02497,
  0.00562,
  0.00014,
  -0.00951,
  0.00972,
  -0.08313,
  -0.02513,
  -0.21225,
  -0.02302,
  -0.0517,
  0.00392,
  -0.01118,
  0.07003,
  0.08349,
  -0.02461,
  -0.00314,
  -0.0899,
  0.00672,
  -0.06612,
  -0.01456,
  0.02753,
  0.01846,
  0.02351,
  0.03367,
  0.01711,
  -0.00742,
  -0.04268,
  -0.03307,
  0.03141,
  -0.02508,
  0.02337,
  -0.09592,
  0.00196,
  0.07172,
  -0.0104,
  -0.02518,
  0.01167,
  0.03244,
  -0.06083,
  0.03383,
  0.08568,
  0.00289,
  -0.00666,
  0.00372,
  -0.01252,
  0.0575,
  0.02342,
  -0.04576,
  0.0203,
  0.01109,
  0.03811,
  -0.02193,
  0.05802,
  -0.02806,
  0.07834,
  0.03708,
  0.09972,
  -0.031,
  0.04375,
  0.04508,
  -0.03037,
  0.00076,
  0.04262,
  -0.06372,
  -0.01377,
  -0.09375,
  -0.07927,
  -0.03695,
  0.03883,
  -0.02006,
  0.02201,
  0.03443,
  0.01749,
  -0.02804,
  -0.01713,
  -0.01357,
  -0.03246,
  -0.00017,
  0.04243,
  -0.0246,
  -0.03114,
  0.00036,
  -0.0091,
  0.02646,
  0.04699,
  -0.00774,
  0.04342,
  -0.05966,
  -0.00093,
  -0.27434,
  0.04228,
  -0.00193,
  -0.06285,
  -0.04824,
  -0.03964,
  -0.00929,
  -0.0286,
  0.08375,
  0.00956,
  -0.01114,
  -0.04103,
  0.0102,
  -0.02959,
  0.00528,
  0.00456,
  0.00894,
  0.01623,
  0.02494,
  0.02719,
  -0.00642,
  0.05057,
  -0.00648,
  -0.02467,
  -0.0035,
  -0.00847,
  0.16253,
  0.13079,
  -0.04903,
  -0.03205,
  -0.00316,
  0.01859,
  -0.02113,
  -0.04417,
  -0.0227,
  0.04514,
  0.03991,
  -0.01545,
  -0.02719,
  -0.06202,
  -0.01737,
  0.02439,
  -0.02732,
  -0.02902,
  -0.04721,
  -0.04591,
  0.06124,
  0.00874,
  -0.01717,
  0.05145,
  0.02084,
  -0.08649,
  -0.00435,
  0.00575,
  -0.02577,
  -0.00093,
  -0.01943,
  0.02053,
  0.01121,
  -0.01203,
  0.01132,
  0.02382,
  -0.04001,
  -0.01554,
  0.00358,
  0.01697,
  -0.0316,
  -0.05977,
  -0.01849,
  -0.03698,
  -0.05359,
  0.00978,
  -0.037,
  -0.03242,
  0.01881,
  0.02396,
  0.06378,
  -0.00201,
  -0.06116,
  0.00661,
  -0.02041,
  -0.00688,
  -0.01759,
  0.05388,
  0.01388,
  -0.00073,
  -0.00265,
  0.00762,
  0.0055,
  -0.02159,
  -0.06811,
  0.05126,
  0.04246,
  0.00851,
  -0.02475,
  -0.00264,
  -0.24022,
  0.03098,
  -0.02896,
  0.09586,
  -0.01219,
  0.0594,
  -0.01466,
  0.05822,
  0.00455,
  -0.01739,
  -0.00339,
  0.03262,
  0.06572,
  0.01241,
  -0.03823,
  0.0393,
  0.07897,
  0.00279,
  0.01404,
  -0.07623,
  0.05825,
  0.00952,
  0.195,
  -0.00605,
  -0.02063,
  -0.04079,
  0.03891,
  0.01302,
  0.00668,
  0.02259,
  -0.02588,
  0.00538,
  0.01366,
  -0.01946,
  -0.01993,
  0.02111,
  -0.00886,
  0.0101,
  0.02732,
  0.01459,
  -0.01308,
  0.05197,
  -0.02153,
  -0.07248,
  0.0884,
  -0.02124,
  -0.02226,
  0.00806,
  -0.02883,
  -0.00794,
  -0.06239,
  0.00698,
  0.08044,
  0.02103,
  -0.00437,
  0.03405,
  0.00347,
  0.09667,
  0.0102,
  0.02466,
  -0.03105,
  -0.02491,
  0.03068,
  0.00883,
  0.00824,
]
`;

exports[`loadModelInfo 1`] = `
{
  "alignment": 32,
  "data_offset": 7819680,
  "general.architecture": "llama",
  "general.basename": "Llama-3.2",
  "general.file_type": "2",
  "general.finetune": "1b",
  "general.name": "Llama 3.2 1B",
  "general.organization": "Meta Llama",
  "general.quantization_version": "2",
  "general.size_label": "73M",
  "general.type": "model",
  "llama.attention.head_count": "8",
  "llama.attention.head_count_kv": "2",
  "llama.attention.key_length": "64",
  "llama.attention.layer_norm_rms_epsilon": "0.000010",
  "llama.attention.value_length": "64",
  "llama.block_count": "2",
  "llama.context_length": "131072",
  "llama.embedding_length": "512",
  "llama.feed_forward_length": "2048",
  "llama.rope.dimension_count": "64",
  "llama.rope.freq_base": "500000.000000",
  "llama.vocab_size": "128256",
  "tokenizer.ggml.bos_token_id": "128000",
  "tokenizer.ggml.eos_token_id": "128001",
  "tokenizer.ggml.model": "gpt2",
  "tokenizer.ggml.pre": "llama-bpe",
  "version": 3,
}
`;

exports[`tokeneize & detokenize & getFormattedChat 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;

exports[`tokeneize & detokenize & getFormattedChat 2`] = `"���"`;

exports[`tokeneize & detokenize & getFormattedChat 3`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`tokeneize & detokenize & getFormattedChat 4`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`works fine with vocab_only: empty result 1`] = `
{
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "",
  "timings": {
    "predicted_ms": 0,
    "predicted_n": 1,
    "predicted_per_second": Infinity,
    "predicted_per_token_ms": 0,
    "prompt_ms": 0,
    "prompt_n": 1,
    "prompt_per_second": Infinity,
    "prompt_per_token_ms": 0,
  },
  "tokens_evaluated": 0,
  "tokens_predicted": 0,
  "truncated": false,
}
`;

exports[`works fine with vocab_only: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 0,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`works fine with vocab_only: tokenize 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;
