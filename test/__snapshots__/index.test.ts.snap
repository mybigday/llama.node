// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`basic completion 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": " swochadoorter scientific WindowsCa occupiedrå alta",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`basic completion: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "llama ?B F16",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.file_type": "1",
    "general.name": "LLaMA v2",
    "llama.attention.head_count": "2",
    "llama.attention.head_count_kv": "2",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.block_count": "1",
    "llama.context_length": "4096",
    "llama.embedding_length": "8",
    "llama.feed_forward_length": "32",
    "llama.rope.dimension_count": "4",
    "tokenizer.ggml.bos_token_id": "1",
    "tokenizer.ggml.eos_token_id": "2",
    "tokenizer.ggml.model": "llama",
    "tokenizer.ggml.unknown_token_id": "0",
  },
  "nEmbd": 8,
  "nParams": 513048,
  "size": 1026144,
}
`;

exports[`completion with response_format: json_object 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{"\` También player et",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 5,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with response_format: json_schema 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{
"name"",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 13,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with tools 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{"tool_call":{"na",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 328,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`embedding: Embedding (normalized) 1`] = `
[
  -0.03405,
  -0.04687,
  0.03055,
  -0.03244,
  0.02572,
  0.00436,
  0.04408,
  0.01124,
  0.04397,
  -0.00677,
  -0.00507,
  0.03017,
  0.04353,
  0.01096,
  0.0527,
  -0.00101,
  -0.0265,
  -0.02448,
  -0.11243,
  -0.02329,
  0.0705,
  -0.07773,
  0.0222,
  0.01387,
  -0.03295,
  -0.00543,
  0.01703,
  -0.02683,
  -0.01997,
  -0.08627,
  -0.01069,
  -0.05166,
  0.03084,
  -0.00314,
  0.01072,
  0.06867,
  -0.01944,
  0.03395,
  -0.01756,
  -0.00794,
  0.00239,
  -0.01318,
  -0.04514,
  -0.06922,
  -0.10232,
  -0.05142,
  -0.00979,
  -0.01146,
  0.02552,
  0.01921,
  -0.00067,
  -0.02684,
  0.05862,
  -0.04511,
  -0.01046,
  0.05617,
  0.063,
  -0.00072,
  0.00508,
  -0.00219,
  0.03063,
  0.00713,
  -0.14483,
  0.08342,
  0.07884,
  0.02701,
  0.02647,
  -0.04202,
  0.05502,
  -0.00352,
  -0.12541,
  0.0065,
  0.04583,
  0.02616,
  0.01007,
  0.10264,
  0.01103,
  -0.02296,
  0.00285,
  -0.00692,
  0.00218,
  0.00001,
  -0.0292,
  0.03159,
  0.03461,
  -0.02341,
  0.01666,
  -0.01687,
  0.06542,
  -0.01397,
  -0.0531,
  -0.01703,
  0.00159,
  0.03727,
  -0.09013,
  -0.04101,
  0.08188,
  -0.05415,
  0.0497,
  0.32549,
  -0.08835,
  0.02756,
  0.05373,
  0.02883,
  0.0411,
  -0.04939,
  0.05327,
  -0.07148,
  0.07842,
  0.02881,
  0.00472,
  -0.07598,
  -0.01287,
  -0.08169,
  0.01151,
  0.05609,
  0.05064,
  -0.03103,
  0.03222,
  0.02246,
  0.02834,
  0.02663,
  -0.03502,
  -0.05691,
  -0.09179,
  -0.06596,
  0.11565,
  0.07813,
  -0.02936,
  -0.02753,
  0.01946,
  -0.00949,
  0.02146,
  0.01797,
  -0.03032,
  -0.01348,
  -0.01537,
  0.00997,
  0.00435,
  -0.07919,
  -0.02756,
  -0.21072,
  -0.03559,
  -0.05842,
  0.00192,
  0.00351,
  0.06553,
  0.09225,
  -0.03419,
  -0.00856,
  -0.07706,
  0.01194,
  -0.06103,
  -0.00187,
  0.0304,
  0.03617,
  0.02201,
  0.02105,
  0.02992,
  -0.01265,
  -0.0226,
  -0.03334,
  0.03609,
  -0.02529,
  0.01916,
  -0.09895,
  0.01099,
  0.05968,
  -0.00261,
  -0.02119,
  0.03903,
  0.02482,
  -0.04532,
  0.02447,
  0.08178,
  0.01289,
  -0.00556,
  0.01038,
  -0.0316,
  0.04967,
  0.02269,
  -0.03095,
  0.02257,
  0.02955,
  0.03861,
  -0.00559,
  0.05748,
  -0.03356,
  0.08196,
  0.05268,
  0.07761,
  -0.0166,
  0.02533,
  0.02806,
  -0.04667,
  0.02338,
  0.0356,
  -0.07074,
  -0.00776,
  -0.10588,
  -0.0622,
  -0.05739,
  0.02132,
  -0.01479,
  0.05687,
  0.03414,
  0.03259,
  -0.01867,
  -0.01331,
  -0.02466,
  -0.0325,
  0.00501,
  0.05681,
  -0.01958,
  -0.03578,
  -0.01716,
  -0.00795,
  0.0232,
  0.0477,
  0.00097,
  0.03242,
  -0.03964,
  0.0028,
  -0.28546,
  0.04396,
  -0.01921,
  -0.02617,
  -0.03748,
  -0.04581,
  -0.00516,
  -0.04648,
  0.04316,
  0.00279,
  -0.02884,
  -0.03575,
  0.02033,
  -0.03551,
  0.00551,
  0.01848,
  0.00766,
  0.02968,
  0.01863,
  0.02705,
  -0.01969,
  0.03112,
  -0.00389,
  -0.0236,
  0.01248,
  -0.00615,
  0.16117,
  0.11753,
  -0.05045,
  -0.03774,
  -0.00893,
  -0.00361,
  -0.03212,
  -0.0381,
  -0.03276,
  0.04119,
  0.04176,
  -0.02137,
  -0.0149,
  -0.06475,
  -0.04073,
  0.01463,
  -0.01943,
  -0.00101,
  -0.08011,
  -0.0447,
  0.0487,
  0.01477,
  -0.03413,
  0.07016,
  0.02643,
  -0.07633,
  -0.01736,
  0.00697,
  -0.02025,
  -0.00785,
  -0.0125,
  0.00338,
  0.00254,
  0.0047,
  0.0286,
  0.04515,
  -0.02918,
  -0.0156,
  0.01586,
  0.01714,
  -0.03206,
  -0.06614,
  -0.00932,
  -0.03969,
  -0.06813,
  0.02326,
  -0.04091,
  -0.02563,
  0.01991,
  0.01826,
  0.05225,
  -0.01035,
  -0.06039,
  0.0164,
  -0.03353,
  -0.01967,
  -0.00289,
  0.05873,
  0.00696,
  0.01717,
  -0.0229,
  0.02082,
  -0.00204,
  -0.00069,
  -0.05991,
  0.03867,
  0.04821,
  -0.00076,
  -0.01772,
  -0.02672,
  -0.24554,
  0.01588,
  -0.04268,
  0.07593,
  -0.01964,
  0.06346,
  -0.0118,
  0.07131,
  0.00549,
  -0.02068,
  -0.00516,
  0.0395,
  0.06139,
  0.01595,
  -0.04581,
  0.03386,
  0.0637,
  -0.00478,
  0.00275,
  -0.07785,
  0.04475,
  0.02045,
  0.1846,
  -0.00428,
  0.00131,
  -0.02855,
  0.02817,
  0.01065,
  0.02267,
  0.03807,
  0.01031,
  0.00651,
  0.01908,
  -0.02294,
  0.00162,
  0.0304,
  -0.0164,
  0.02252,
  0.01547,
  0.01539,
  -0.0376,
  0.04615,
  -0.0145,
  -0.06704,
  0.08572,
  -0.00033,
  -0.01757,
  -0.00022,
  -0.04407,
  -0.01799,
  -0.05275,
  -0.01068,
  0.08437,
  0.03656,
  -0.00723,
  0.0394,
  -0.00303,
  0.08886,
  0.0127,
  0.02196,
  0.00665,
  -0.00809,
  0.03229,
  -0.0097,
  0.00345,
]
`;

exports[`loadModelInfo 1`] = `
{
  "alignment": 32,
  "data_offset": 724416,
  "general.architecture": "llama",
  "general.file_type": "1",
  "general.name": "LLaMA v2",
  "llama.attention.head_count": "2",
  "llama.attention.head_count_kv": "2",
  "llama.attention.layer_norm_rms_epsilon": "0.000010",
  "llama.block_count": "1",
  "llama.context_length": "4096",
  "llama.embedding_length": "8",
  "llama.feed_forward_length": "32",
  "llama.rope.dimension_count": "4",
  "tokenizer.ggml.bos_token_id": "1",
  "tokenizer.ggml.eos_token_id": "2",
  "tokenizer.ggml.model": "llama",
  "tokenizer.ggml.unknown_token_id": "0",
  "version": 3,
}
`;

exports[`tokeneize & detokenize & getFormattedChat 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    9038,
    2501,
    263,
    931,
  ],
}
`;

exports[`tokeneize & detokenize & getFormattedChat 2`] = `"xxx"`;

exports[`tokeneize & detokenize & getFormattedChat 3`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`tokeneize & detokenize & getFormattedChat 4`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`works fine with vocab_only: empty result 1`] = `
{
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "",
  "timings": {
    "predicted_ms": 0,
    "predicted_n": 1,
    "predicted_per_second": Infinity,
    "predicted_per_token_ms": 0,
    "prompt_ms": 0,
    "prompt_n": 1,
    "prompt_per_second": Infinity,
    "prompt_per_token_ms": 0,
  },
  "tokens_evaluated": 0,
  "tokens_predicted": 0,
  "truncated": false,
}
`;

exports[`works fine with vocab_only: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.file_type": "1",
    "general.name": "LLaMA v2",
    "llama.attention.head_count": "2",
    "llama.attention.head_count_kv": "2",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.block_count": "1",
    "llama.context_length": "4096",
    "llama.embedding_length": "8",
    "llama.feed_forward_length": "32",
    "llama.rope.dimension_count": "4",
    "tokenizer.ggml.bos_token_id": "1",
    "tokenizer.ggml.eos_token_id": "2",
    "tokenizer.ggml.model": "llama",
    "tokenizer.ggml.unknown_token_id": "0",
  },
  "nEmbd": 0,
  "nParams": 513048,
  "size": 1026144,
}
`;

exports[`works fine with vocab_only: tokenize 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    9038,
    2501,
    263,
    931,
  ],
}
`;
