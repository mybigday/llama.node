// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`basic completion 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "wallwallwallwallwallwallwallwallwallwall",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`basic completion: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "llama ?B Q4_0",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 512,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`completion with response_format: json_object 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{}
		              			<|eot_id|>",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 4,
  "tokens_predicted": 4,
  "truncated": false,
}
`;

exports[`completion with response_format: json_schema 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{
 				 				 				 				",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 13,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with t5-like model 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": " How old sind er?</s>",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 7,
  "truncated": false,
}
`;

exports[`completion with tools 1`] = `
{
  "additional_stops": [],
  "chat_format": 9,
  "grammar": "any-tool-call ::= ( calc-call ) space
calc-args ::= "{" space  (calc-args-expression-kv )? "}" space
calc-args-expression-kv ::= "\\"expression\\"" space ":" space string
calc-call ::= "{" space calc-call-name-kv "," space calc-call-arguments-kv "}" space
calc-call-arguments ::= "{" space  (calc-call-arguments-expression-kv )? "}" space
calc-call-arguments-expression-kv ::= "\\"expression\\"" space ":" space string
calc-call-arguments-kv ::= "\\"arguments\\"" space ":" space calc-call-arguments
calc-call-name ::= "\\"calc\\"" space
calc-call-name-kv ::= "\\"name\\"" space ":" space calc-call-name
calc-function-tag ::= "<function" ( "=calc" | " name=\\"calc\\"" ) ">" space calc-args "</function>" space
char ::= [^"\\\\\\x7F\\x00-\\x1F] | [\\\\] (["\\\\bfnrt] | "u" [0-9a-fA-F]{4})
root ::= tool-call
space ::= | " " | "\\n"{1,2} [ \\t]{0,20}
string ::= "\\"" char* "\\"" space
tool-call ::= calc-function-tag | wrappable-tool-call | ( "\`\`\`\\n" | "\`\`\`json\\n" | "\`\`\`xml\\n" ) space wrappable-tool-call space "\`\`\`" space 
wrappable-tool-call ::= ( any-tool-call | "<tool_call>" space any-tool-call "</tool_call>" | "<function_call>" space any-tool-call "</function_call>" | "<response>"  space any-tool-call "</response>" | "<tools>"     space any-tool-call "</tools>" | "<json>"      space any-tool-call "</json>" | "<xml>"      space any-tool-call "</xml>" | "<JSON>"      space any-tool-call "</JSON>" ) space
",
  "grammar_triggers": [
    {
      "token": -1,
      "type": 1,
      "value": "<function=calc>",
    },
    {
      "token": -1,
      "type": 2,
      "value": "<function\\s+name\\s*=\\s*"calc"",
    },
    {
      "token": -1,
      "type": 3,
      "value": "(?:<think>[\\s\\S]*?</think>\\s*)?(\\s*(?:<tool_call>|<function|(?:\`\`\`(?:json|xml)?
\\s*)?(?:<function_call>|<tools>|<xml><json>|<response>)?\\s*\\{\\s*"name"\\s*:\\s*"(?:calc)"))[\\s\\S]*",
    },
  ],
  "grammea_lazy": true,
  "has_media": false,
  "media_paths": [],
  "preserved_tokens": [
    "<think>",
    "</think>",
    "<tool_call>",
    "</tool_call>",
    "<function",
    "<tools>",
    "</tools>",
    "<response>",
    "</response>",
    "<function_call>",
    "</function_call>",
    "<json>",
    "</json>",
    "<JSON>",
    "</JSON>",
    "\`\`\`",
    "\`\`\`json",
    "\`\`\`xml",
  ],
  "prompt": "<|im_start|>system
# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"type": "function", "function": {"name": "calc", "description": "Calculates the result of a math expression.", "parameters": {"type": "object", "properties": {"expression": {"type": "string", "description": "The math expression to evaluate."}}}}}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call><|im_end|>
<|im_start|>user
What is the sum of 1 and 2?<|im_end|>
<|im_start|>assistant
",
  "thinking_forced_open": false,
  "type": "jinja",
}
`;

exports[`embedding: Embedding (normalized) 1`] = `
[
  -0.02608,
  -0.01893,
  0.04275,
  -0.03942,
  0.02394,
  0.01366,
  0.03257,
  -0.00062,
  0.04486,
  -0.00371,
  -0.01114,
  0.02767,
  0.02767,
  0.02348,
  0.03236,
  -0.01622,
  -0.02583,
  -0.04106,
  -0.1222,
  -0.00434,
  0.07816,
  -0.08039,
  0.02338,
  0.03078,
  0.01224,
  0.01664,
  0.00953,
  -0.04332,
  -0.03609,
  -0.09791,
  -0.00971,
  -0.04234,
  0.03434,
  -0.00963,
  0.00537,
  0.07464,
  -0.02403,
  0.04451,
  -0.00575,
  -0.01929,
  0.00299,
  -0.01408,
  -0.05636,
  -0.05345,
  -0.08812,
  -0.03412,
  -0.02175,
  0.00955,
  0.03639,
  0.01938,
  -0.00792,
  -0.04004,
  0.05272,
  -0.01699,
  -0.02006,
  0.05142,
  0.05659,
  -0.01134,
  0.02976,
  -0.00247,
  0.03062,
  0.01843,
  -0.1345,
  0.08546,
  0.08895,
  0.02677,
  0.03063,
  -0.03968,
  0.03112,
  -0.02526,
  -0.0997,
  0.00391,
  0.04543,
  0.02417,
  0.01873,
  0.09942,
  0.00287,
  -0.03371,
  0.00088,
  -0.02772,
  -0.0013,
  0.005,
  -0.02006,
  0.04737,
  0.05001,
  -0.00489,
  -0.00977,
  -0.03482,
  0.0708,
  -0.01361,
  -0.06405,
  -0.01273,
  -0.00688,
  0.04866,
  -0.08215,
  -0.02916,
  0.07291,
  -0.05826,
  0.03562,
  0.32587,
  -0.09712,
  0.03687,
  0.04516,
  0.03372,
  0.0404,
  -0.03384,
  0.05798,
  -0.07942,
  0.06954,
  0.0122,
  0.01385,
  -0.08994,
  -0.01864,
  -0.08012,
  -0.00929,
  0.06822,
  0.04621,
  -0.00656,
  0.01885,
  0.03248,
  0.01567,
  0.03128,
  -0.03159,
  -0.05678,
  -0.07645,
  -0.06655,
  0.11815,
  0.05572,
  -0.02104,
  -0.04186,
  0.03118,
  -0.01313,
  0.00642,
  0.01667,
  -0.0247,
  0.00564,
  -0.00039,
  -0.0094,
  0.00991,
  -0.08332,
  -0.02496,
  -0.21221,
  -0.02302,
  -0.05199,
  0.00391,
  -0.01102,
  0.07032,
  0.08321,
  -0.02487,
  -0.00353,
  -0.08975,
  0.00679,
  -0.06603,
  -0.01454,
  0.02707,
  0.01809,
  0.02356,
  0.03357,
  0.01728,
  -0.00766,
  -0.04281,
  -0.0333,
  0.03185,
  -0.025,
  0.02352,
  -0.09618,
  0.00182,
  0.07186,
  -0.0102,
  -0.0247,
  0.01172,
  0.03254,
  -0.06107,
  0.03361,
  0.08574,
  0.00281,
  -0.0071,
  0.00355,
  -0.0123,
  0.05737,
  0.02337,
  -0.04569,
  0.0204,
  0.01094,
  0.0385,
  -0.02196,
  0.05778,
  -0.02804,
  0.07856,
  0.03714,
  0.09947,
  -0.03106,
  0.04375,
  0.04513,
  -0.03016,
  -0.00007,
  0.04229,
  -0.06346,
  -0.0138,
  -0.09411,
  -0.07913,
  -0.03699,
  0.03877,
  -0.02027,
  0.0223,
  0.03449,
  0.0178,
  -0.02785,
  -0.01704,
  -0.01342,
  -0.03238,
  -0.00007,
  0.04257,
  -0.02461,
  -0.03121,
  0.00027,
  -0.00911,
  0.02591,
  0.04678,
  -0.00789,
  0.0434,
  -0.05992,
  -0.00132,
  -0.27431,
  0.04219,
  -0.0017,
  -0.06275,
  -0.04763,
  -0.0398,
  -0.00904,
  -0.02863,
  0.08345,
  0.00944,
  -0.01127,
  -0.04071,
  0.01037,
  -0.02973,
  0.00511,
  0.00423,
  0.009,
  0.01615,
  0.02502,
  0.02714,
  -0.00628,
  0.05073,
  -0.00684,
  -0.02481,
  -0.00357,
  -0.00862,
  0.16254,
  0.1307,
  -0.04859,
  -0.03209,
  -0.00304,
  0.01841,
  -0.02127,
  -0.04414,
  -0.02272,
  0.04558,
  0.04014,
  -0.0152,
  -0.02725,
  -0.06181,
  -0.0171,
  0.02436,
  -0.02716,
  -0.02885,
  -0.04756,
  -0.04599,
  0.06136,
  0.00844,
  -0.01744,
  0.05134,
  0.02081,
  -0.08642,
  -0.00428,
  0.00607,
  -0.0259,
  -0.00085,
  -0.0197,
  0.02052,
  0.01133,
  -0.01223,
  0.01156,
  0.0237,
  -0.03978,
  -0.0152,
  0.00359,
  0.01672,
  -0.03138,
  -0.05977,
  -0.01819,
  -0.03712,
  -0.05355,
  0.00956,
  -0.03678,
  -0.03245,
  0.01861,
  0.02445,
  0.0638,
  -0.00216,
  -0.06154,
  0.0067,
  -0.0202,
  -0.00699,
  -0.01804,
  0.054,
  0.01378,
  -0.00064,
  -0.00245,
  0.00752,
  0.00547,
  -0.02115,
  -0.06811,
  0.05134,
  0.04237,
  0.00901,
  -0.02465,
  -0.00222,
  -0.24015,
  0.03106,
  -0.02845,
  0.09561,
  -0.01264,
  0.05921,
  -0.01459,
  0.05825,
  0.00499,
  -0.01769,
  -0.00336,
  0.03281,
  0.06573,
  0.0124,
  -0.03805,
  0.0396,
  0.0791,
  0.00251,
  0.0141,
  -0.0762,
  0.05812,
  0.00945,
  0.19532,
  -0.00642,
  -0.02059,
  -0.04098,
  0.03901,
  0.01286,
  0.00691,
  0.02245,
  -0.02536,
  0.00553,
  0.01358,
  -0.01944,
  -0.01986,
  0.02093,
  -0.00863,
  0.01033,
  0.02764,
  0.01462,
  -0.01292,
  0.05184,
  -0.02175,
  -0.07225,
  0.08823,
  -0.02153,
  -0.02274,
  0.00821,
  -0.02892,
  -0.00753,
  -0.06198,
  0.00699,
  0.08033,
  0.02182,
  -0.00421,
  0.03469,
  0.00404,
  0.09726,
  0.00998,
  0.02425,
  -0.03087,
  -0.0248,
  0.03083,
  0.00886,
  0.00799,
]
`;

exports[`loadModelInfo 1`] = `
{
  "alignment": 32,
  "data_offset": 7819680,
  "general.architecture": "llama",
  "general.basename": "Llama-3.2",
  "general.file_type": "2",
  "general.finetune": "1b",
  "general.name": "Llama 3.2 1B",
  "general.organization": "Meta Llama",
  "general.quantization_version": "2",
  "general.size_label": "73M",
  "general.type": "model",
  "llama.attention.head_count": "8",
  "llama.attention.head_count_kv": "2",
  "llama.attention.key_length": "64",
  "llama.attention.layer_norm_rms_epsilon": "0.000010",
  "llama.attention.value_length": "64",
  "llama.block_count": "2",
  "llama.context_length": "131072",
  "llama.embedding_length": "512",
  "llama.feed_forward_length": "2048",
  "llama.rope.dimension_count": "64",
  "llama.rope.freq_base": "500000.000000",
  "llama.vocab_size": "128256",
  "tokenizer.ggml.bos_token_id": "128000",
  "tokenizer.ggml.eos_token_id": "128001",
  "tokenizer.ggml.model": "gpt2",
  "tokenizer.ggml.pre": "llama-bpe",
  "version": 3,
}
`;

exports[`tokeneize & detokenize & getFormattedChat 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;

exports[`tokeneize & detokenize & getFormattedChat 2`] = `"���"`;

exports[`tokeneize & detokenize & getFormattedChat 3`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`tokeneize & detokenize & getFormattedChat 4`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`works fine with vocab_only: empty result 1`] = `
{
  "chat_format": 0,
  "context_full": false,
  "interrupted": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "",
  "timings": {
    "predicted_ms": 0,
    "predicted_n": 1,
    "predicted_per_second": Infinity,
    "predicted_per_token_ms": 0,
    "prompt_ms": 0,
    "prompt_n": 1,
    "prompt_per_second": Infinity,
    "prompt_per_token_ms": 0,
  },
  "tokens_evaluated": 0,
  "tokens_predicted": 0,
  "truncated": false,
}
`;

exports[`works fine with vocab_only: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 0,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`works fine with vocab_only: tokenize 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;
