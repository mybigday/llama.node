// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`basic completion 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "wallwallwallwallwallwallwallwallwallwall",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`basic completion: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "llama ?B Q4_0",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 512,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`completion with response_format: json_object 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{}
		              			<|eot_id|>",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 4,
  "tokens_predicted": 4,
  "truncated": false,
}
`;

exports[`completion with response_format: json_schema 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{
 				 				 				 				",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 13,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with tools 1`] = `
{
  "content": "<removed>",
  "context_full": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": "<tool_call>
{"name": "calc", "arguments": {"expression": "1 + 2"}}
</tool_call>
<|im_end|>",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 213,
  "tokens_predicted": 23,
  "tool_calls": [
    {
      "function": {
        "arguments": "{"expression":"1 + 2"}",
        "name": "calc",
      },
      "type": "function",
    },
  ],
  "truncated": false,
}
`;

exports[`embedding: Embedding (normalized) 1`] = `
[
  -0.0262,
  -0.01996,
  0.042,
  -0.03951,
  0.0241,
  0.01469,
  0.0324,
  -0.00024,
  0.0452,
  -0.00347,
  -0.01172,
  0.02827,
  0.02846,
  0.02534,
  0.03322,
  -0.01526,
  -0.02565,
  -0.04042,
  -0.12237,
  -0.00405,
  0.07824,
  -0.08007,
  0.02328,
  0.03113,
  0.01419,
  0.0167,
  0.01027,
  -0.04409,
  -0.03695,
  -0.09913,
  -0.0105,
  -0.04133,
  0.03561,
  -0.00923,
  0.00398,
  0.07246,
  -0.02333,
  0.04458,
  -0.00737,
  -0.02051,
  0.00425,
  -0.01389,
  -0.05758,
  -0.05335,
  -0.08833,
  -0.03336,
  -0.02129,
  0.00956,
  0.03598,
  0.01947,
  -0.0075,
  -0.03976,
  0.05217,
  -0.0168,
  -0.02017,
  0.05098,
  0.05707,
  -0.01159,
  0.0287,
  -0.00232,
  0.0315,
  0.01672,
  -0.13274,
  0.08625,
  0.08959,
  0.02658,
  0.03014,
  -0.0387,
  0.03166,
  -0.02732,
  -0.09929,
  0.00393,
  0.04624,
  0.0225,
  0.01835,
  0.10051,
  0.00366,
  -0.03369,
  0.00081,
  -0.02736,
  -0.00028,
  0.00497,
  -0.02062,
  0.04795,
  0.0505,
  -0.00505,
  -0.01083,
  -0.03632,
  0.07009,
  -0.01383,
  -0.06251,
  -0.01301,
  -0.0063,
  0.04898,
  -0.08285,
  -0.02799,
  0.07298,
  -0.0591,
  0.03489,
  0.32585,
  -0.09637,
  0.03742,
  0.04627,
  0.03363,
  0.04132,
  -0.03291,
  0.05881,
  -0.07892,
  0.06968,
  0.01192,
  0.01468,
  -0.08967,
  -0.01638,
  -0.08141,
  -0.00697,
  0.06873,
  0.0452,
  -0.00533,
  0.01892,
  0.0319,
  0.01553,
  0.03081,
  -0.03167,
  -0.05702,
  -0.07625,
  -0.06609,
  0.11928,
  0.05489,
  -0.02097,
  -0.04123,
  0.03077,
  -0.01138,
  0.00613,
  0.01783,
  -0.02584,
  0.00554,
  -0.00057,
  -0.01003,
  0.00959,
  -0.0842,
  -0.02452,
  -0.21226,
  -0.02393,
  -0.05186,
  0.00483,
  -0.01116,
  0.07002,
  0.08239,
  -0.02683,
  -0.00361,
  -0.08912,
  0.00527,
  -0.06624,
  -0.01397,
  0.02521,
  0.01772,
  0.02451,
  0.03316,
  0.01688,
  -0.00725,
  -0.04462,
  -0.0334,
  0.03034,
  -0.02576,
  0.02371,
  -0.09754,
  0.00335,
  0.07242,
  -0.01094,
  -0.0247,
  0.01231,
  0.03186,
  -0.06018,
  0.03249,
  0.08493,
  0.004,
  -0.0061,
  0.0042,
  -0.01144,
  0.05636,
  0.02248,
  -0.04467,
  0.02097,
  0.01212,
  0.03704,
  -0.02148,
  0.05864,
  -0.0271,
  0.07879,
  0.03743,
  0.09953,
  -0.03064,
  0.04317,
  0.04542,
  -0.03095,
  -0.00105,
  0.04216,
  -0.06545,
  -0.01342,
  -0.09424,
  -0.07888,
  -0.03781,
  0.03986,
  -0.02185,
  0.02135,
  0.03438,
  0.01491,
  -0.02667,
  -0.01893,
  -0.01313,
  -0.03306,
  0.00081,
  0.04224,
  -0.02447,
  -0.03055,
  -0.00089,
  -0.0084,
  0.02419,
  0.0451,
  -0.00793,
  0.04334,
  -0.05889,
  -0.00057,
  -0.27362,
  0.04149,
  -0.00301,
  -0.06191,
  -0.04835,
  -0.04105,
  -0.00878,
  -0.02967,
  0.08437,
  0.0095,
  -0.01155,
  -0.0405,
  0.01019,
  -0.03032,
  0.00507,
  0.00285,
  0.00992,
  0.0168,
  0.02539,
  0.02645,
  -0.00575,
  0.04935,
  -0.00777,
  -0.02418,
  -0.00241,
  -0.00817,
  0.16323,
  0.13022,
  -0.04769,
  -0.03189,
  -0.0037,
  0.01811,
  -0.02135,
  -0.04546,
  -0.022,
  0.04574,
  0.04086,
  -0.01542,
  -0.02707,
  -0.06438,
  -0.0173,
  0.02419,
  -0.02579,
  -0.02872,
  -0.04778,
  -0.04589,
  0.06069,
  0.00868,
  -0.01798,
  0.05253,
  0.02068,
  -0.08697,
  -0.00458,
  0.00475,
  -0.0259,
  -0.00038,
  -0.01823,
  0.01961,
  0.01137,
  -0.01299,
  0.01204,
  0.02543,
  -0.04017,
  -0.01541,
  0.00368,
  0.01633,
  -0.03109,
  -0.05947,
  -0.01818,
  -0.03935,
  -0.05374,
  0.00899,
  -0.03634,
  -0.03181,
  0.01875,
  0.02581,
  0.06475,
  -0.00209,
  -0.06115,
  0.00714,
  -0.02033,
  -0.00545,
  -0.01726,
  0.05307,
  0.01428,
  0.00152,
  -0.00245,
  0.00836,
  0.00379,
  -0.02098,
  -0.06851,
  0.05129,
  0.04143,
  0.00874,
  -0.02517,
  -0.00189,
  -0.24045,
  0.03158,
  -0.02814,
  0.09534,
  -0.0125,
  0.05857,
  -0.01356,
  0.05815,
  0.00634,
  -0.01774,
  -0.00289,
  0.03314,
  0.06638,
  0.01069,
  -0.03936,
  0.03976,
  0.0786,
  0.00296,
  0.01386,
  -0.0759,
  0.05767,
  0.00977,
  0.19456,
  -0.00757,
  -0.02151,
  -0.04003,
  0.03999,
  0.01273,
  0.00812,
  0.02199,
  -0.02546,
  0.0053,
  0.01307,
  -0.01888,
  -0.0202,
  0.02195,
  -0.00963,
  0.01106,
  0.02828,
  0.01489,
  -0.01215,
  0.05055,
  -0.02071,
  -0.07158,
  0.08861,
  -0.02067,
  -0.02205,
  0.00897,
  -0.02894,
  -0.00818,
  -0.06224,
  0.00649,
  0.08042,
  0.02284,
  -0.00382,
  0.03494,
  0.00281,
  0.09735,
  0.00941,
  0.02273,
  -0.0316,
  -0.02409,
  0.02958,
  0.00838,
  0.00892,
]
`;

exports[`loadModelInfo 1`] = `
{
  "alignment": 32,
  "data_offset": 7819680,
  "general.architecture": "llama",
  "general.basename": "Llama-3.2",
  "general.file_type": "2",
  "general.finetune": "1b",
  "general.name": "Llama 3.2 1B",
  "general.organization": "Meta Llama",
  "general.quantization_version": "2",
  "general.size_label": "73M",
  "general.type": "model",
  "llama.attention.head_count": "8",
  "llama.attention.head_count_kv": "2",
  "llama.attention.key_length": "64",
  "llama.attention.layer_norm_rms_epsilon": "0.000010",
  "llama.attention.value_length": "64",
  "llama.block_count": "2",
  "llama.context_length": "131072",
  "llama.embedding_length": "512",
  "llama.feed_forward_length": "2048",
  "llama.rope.dimension_count": "64",
  "llama.rope.freq_base": "500000.000000",
  "llama.vocab_size": "128256",
  "tokenizer.ggml.bos_token_id": "128000",
  "tokenizer.ggml.eos_token_id": "128001",
  "tokenizer.ggml.model": "gpt2",
  "tokenizer.ggml.pre": "llama-bpe",
  "version": 3,
}
`;

exports[`tokeneize & detokenize & getFormattedChat 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;

exports[`tokeneize & detokenize & getFormattedChat 2`] = `"���"`;

exports[`tokeneize & detokenize & getFormattedChat 3`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`tokeneize & detokenize & getFormattedChat 4`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`works fine with vocab_only: empty result 1`] = `
{
  "context_full": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "",
  "timings": {
    "predicted_ms": 0,
    "predicted_n": 1,
    "predicted_per_second": Infinity,
    "predicted_per_token_ms": 0,
    "prompt_ms": 0,
    "prompt_n": 1,
    "prompt_per_second": Infinity,
    "prompt_per_token_ms": 0,
  },
  "tokens_evaluated": 0,
  "tokens_predicted": 0,
  "truncated": false,
}
`;

exports[`works fine with vocab_only: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 0,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`works fine with vocab_only: tokenize 1`] = `
{
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;
