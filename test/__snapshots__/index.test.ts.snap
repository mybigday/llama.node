// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`basic completion 1`] = `
{
  "text": " swochadoorter scientific WindowsCa occupiedrå alta",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`basic completion: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "llama ?B F16",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.file_type": "1",
    "general.name": "LLaMA v2",
    "llama.attention.head_count": "2",
    "llama.attention.head_count_kv": "2",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.block_count": "1",
    "llama.context_length": "4096",
    "llama.embedding_length": "8",
    "llama.feed_forward_length": "32",
    "llama.rope.dimension_count": "4",
    "tokenizer.ggml.bos_token_id": "1",
    "tokenizer.ggml.eos_token_id": "2",
    "tokenizer.ggml.model": "llama",
    "tokenizer.ggml.unknown_token_id": "0",
  },
  "nEmbd": 8,
  "nParams": 513048,
  "size": 1026144,
}
`;

exports[`completion with response_format: json_object 1`] = `
{
  "text": "{"\` También player et",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 5,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with response_format: json_schema 1`] = `
{
  "text": "{
"name"",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 13,
  "tokens_predicted": 5,
  "truncated": false,
}
`;

exports[`completion with tools 1`] = `
{
  "text": "{"tool_call":{"na",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 328,
  "tokens_predicted": 10,
  "truncated": false,
}
`;

exports[`embedding: Embedding (normalized) 1`] = `
[
  -0.034051,
  -0.04687,
  0.030553,
  -0.032443,
  0.025718,
  0.004355,
  0.044083,
  0.011238,
  0.043973,
  -0.006768,
  -0.005066,
  0.03017,
  0.043528,
  0.010959,
  0.052704,
  -0.001007,
  -0.026504,
  -0.024478,
  -0.112428,
  -0.023294,
  0.070497,
  -0.077727,
  0.022199,
  0.013874,
  -0.032953,
  -0.005434,
  0.017031,
  -0.026835,
  -0.019972,
  -0.08627,
  -0.010685,
  -0.05166,
  0.030845,
  -0.003137,
  0.010716,
  0.068667,
  -0.019436,
  0.033951,
  -0.017558,
  -0.007935,
  0.002395,
  -0.013179,
  -0.045141,
  -0.069219,
  -0.102325,
  -0.051418,
  -0.009789,
  -0.011456,
  0.025521,
  0.019212,
  -0.000668,
  -0.026835,
  0.058618,
  -0.04511,
  -0.010463,
  0.056169,
  0.063002,
  -0.00072,
  0.005079,
  -0.002192,
  0.030627,
  0.007129,
  -0.144833,
  0.083417,
  0.078844,
  0.027009,
  0.026469,
  -0.042019,
  0.055019,
  -0.003517,
  -0.125409,
  0.006497,
  0.045827,
  0.026156,
  0.01007,
  0.102638,
  0.011027,
  -0.022959,
  0.002852,
  -0.006919,
  0.002179,
  0.00001,
  -0.029202,
  0.031593,
  0.034609,
  -0.023405,
  0.016662,
  -0.016871,
  0.065423,
  -0.013975,
  -0.053096,
  -0.01703,
  0.001586,
  0.037272,
  -0.090131,
  -0.041011,
  0.081881,
  -0.054153,
  0.049705,
  0.325492,
  -0.088346,
  0.027564,
  0.053735,
  0.028829,
  0.041099,
  -0.04939,
  0.05327,
  -0.071485,
  0.07842,
  0.028815,
  0.004722,
  -0.075979,
  -0.012871,
  -0.081686,
  0.011513,
  0.056093,
  0.050636,
  -0.03103,
  0.032218,
  0.022461,
  0.028343,
  0.026634,
  -0.035025,
  -0.056909,
  -0.091795,
  -0.065962,
  0.115646,
  0.078125,
  -0.029365,
  -0.027534,
  0.019464,
  -0.009487,
  0.021463,
  0.017974,
  -0.030323,
  -0.013485,
  -0.015366,
  0.009974,
  0.004347,
  -0.079188,
  -0.027557,
  -0.210718,
  -0.035589,
  -0.058418,
  0.001922,
  0.003506,
  0.065528,
  0.09225,
  -0.034195,
  -0.008564,
  -0.077062,
  0.011937,
  -0.061031,
  -0.00187,
  0.030404,
  0.036169,
  0.022006,
  0.021046,
  0.029922,
  -0.012652,
  -0.022601,
  -0.03334,
  0.036087,
  -0.025288,
  0.019156,
  -0.098949,
  0.010994,
  0.05968,
  -0.002605,
  -0.021187,
  0.039027,
  0.024819,
  -0.045319,
  0.024467,
  0.081776,
  0.012894,
  -0.005557,
  0.010385,
  -0.031597,
  0.049669,
  0.022692,
  -0.030946,
  0.022567,
  0.029549,
  0.038608,
  -0.005588,
  0.057484,
  -0.03356,
  0.081958,
  0.052682,
  0.077608,
  -0.0166,
  0.025334,
  0.028056,
  -0.046674,
  0.023382,
  0.035603,
  -0.070743,
  -0.007758,
  -0.105885,
  -0.062201,
  -0.057385,
  0.021315,
  -0.014794,
  0.056868,
  0.034144,
  0.032595,
  -0.018666,
  -0.013307,
  -0.024665,
  -0.032501,
  0.005007,
  0.056813,
  -0.019577,
  -0.035778,
  -0.017163,
  -0.007953,
  0.023204,
  0.047703,
  0.000972,
  0.03242,
  -0.039637,
  0.0028,
  -0.285457,
  0.043957,
  -0.019212,
  -0.026172,
  -0.037484,
  -0.045813,
  -0.005157,
  -0.046481,
  0.043157,
  0.002795,
  -0.028844,
  -0.035748,
  0.020329,
  -0.035511,
  0.005506,
  0.018476,
  0.007661,
  0.029678,
  0.01863,
  0.027054,
  -0.019695,
  0.031123,
  -0.003889,
  -0.023604,
  0.012483,
  -0.00615,
  0.161169,
  0.117534,
  -0.050453,
  -0.037737,
  -0.008925,
  -0.003609,
  -0.03212,
  -0.038096,
  -0.032761,
  0.041192,
  0.041758,
  -0.021365,
  -0.014902,
  -0.064745,
  -0.040731,
  0.014635,
  -0.019434,
  -0.001013,
  -0.080113,
  -0.044697,
  0.048698,
  0.014775,
  -0.034132,
  0.070158,
  0.026431,
  -0.076332,
  -0.017364,
  0.006974,
  -0.020255,
  -0.00785,
  -0.012498,
  0.003376,
  0.002536,
  0.004697,
  0.0286,
  0.045149,
  -0.029183,
  -0.0156,
  0.01586,
  0.01714,
  -0.032059,
  -0.066136,
  -0.009324,
  -0.039687,
  -0.068127,
  0.023256,
  -0.040906,
  -0.025629,
  0.019907,
  0.018261,
  0.052254,
  -0.010348,
  -0.060386,
  0.016404,
  -0.033528,
  -0.019666,
  -0.002893,
  0.058731,
  0.006958,
  0.017173,
  -0.022898,
  0.020824,
  -0.002041,
  -0.00069,
  -0.059911,
  0.038675,
  0.048214,
  -0.000764,
  -0.017719,
  -0.02672,
  -0.24554,
  0.015877,
  -0.042678,
  0.075932,
  -0.019639,
  0.063455,
  -0.0118,
  0.071312,
  0.005492,
  -0.020676,
  -0.005159,
  0.039505,
  0.061394,
  0.015951,
  -0.045812,
  0.033859,
  0.063696,
  -0.004781,
  0.002747,
  -0.077845,
  0.044752,
  0.020449,
  0.184598,
  -0.00428,
  0.001307,
  -0.028546,
  0.028174,
  0.01065,
  0.022673,
  0.038067,
  0.010307,
  0.006514,
  0.019082,
  -0.022936,
  0.001622,
  0.030405,
  -0.016405,
  0.022523,
  0.015469,
  0.015386,
  -0.037599,
  0.046147,
  -0.014496,
  -0.067044,
  0.085719,
  -0.000328,
  -0.017571,
  -0.000221,
  -0.044069,
  -0.017989,
  -0.05275,
  -0.010677,
  0.084367,
  0.036558,
  -0.007232,
  0.039397,
  -0.00303,
  0.088861,
  0.012701,
  0.021957,
  0.006648,
  -0.008095,
  0.032285,
  -0.009701,
  0.003453,
]
`;

exports[`loadModelInfo 1`] = `
{
  "alignment": 32,
  "data_offset": 724416,
  "general.architecture": "llama",
  "general.file_type": "1",
  "general.name": "LLaMA v2",
  "llama.attention.head_count": "2",
  "llama.attention.head_count_kv": "2",
  "llama.attention.layer_norm_rms_epsilon": "0.000010",
  "llama.block_count": "1",
  "llama.context_length": "4096",
  "llama.embedding_length": "8",
  "llama.feed_forward_length": "32",
  "llama.rope.dimension_count": "4",
  "tokenizer.ggml.bos_token_id": "1",
  "tokenizer.ggml.eos_token_id": "2",
  "tokenizer.ggml.model": "llama",
  "tokenizer.ggml.unknown_token_id": "0",
  "version": 3,
}
`;

exports[`tokeneize & detokenize & getFormattedChat 1`] = `
{
  "tokens": Int32Array [
    9038,
    2501,
    263,
    931,
  ],
}
`;

exports[`tokeneize & detokenize & getFormattedChat 2`] = `"xxx"`;

exports[`tokeneize & detokenize & getFormattedChat 3`] = `
"<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
"
`;

exports[`tokeneize & detokenize & getFormattedChat 4`] = `
{
  "additional_stops": [],
  "chat_format": 1,
  "grammar": "alternative-0 ::= "{" space alternative-0-tool-call-kv "}" space
alternative-0-tool-call ::= "{" space alternative-0-tool-call-name-kv "," space alternative-0-tool-call-arguments-kv "}" space
alternative-0-tool-call-arguments ::= "{" space alternative-0-tool-call-arguments-code-kv "}" space
alternative-0-tool-call-arguments-code-kv ::= "\\"code\\"" space ":" space string
alternative-0-tool-call-arguments-kv ::= "\\"arguments\\"" space ":" space alternative-0-tool-call-arguments
alternative-0-tool-call-kv ::= "\\"tool_call\\"" space ":" space alternative-0-tool-call
alternative-0-tool-call-name ::= "\\"ipython\\"" space
alternative-0-tool-call-name-kv ::= "\\"name\\"" space ":" space alternative-0-tool-call-name
alternative-1 ::= "{" space alternative-1-response-kv "}" space
alternative-1-response-kv ::= "\\"response\\"" space ":" space string
char ::= [^"\\\\\\x7F\\x00-\\x1F] | [\\\\] (["\\\\bfnrt] | "u" [0-9a-fA-F]{4})
root ::= alternative-0 | alternative-1
space ::= | " " | "\\n" [ \\t]{0,20}
string ::= "\\"" char* "\\"" space
",
  "grammar_triggers": [],
  "grammea_lazy": false,
  "preserved_tokens": [],
  "prompt": "<|im_start|>system
Respond in JSON format, either with \`tool_call\` (a request to call tools) or with \`response\` reply to the user's request

You can call any of the following tools to satisfy the user's requests: [
  {
    "type": "function",
    "function": {
      "name": "ipython",
      "description": "Runs code in an ipython interpreter and returns the result of the execution after 60 seconds.",
      "parameters": {
        "type": "object",
        "properties": {
          "code": {
            "type": "string",
            "description": "The code to run in the ipython interpreter."
          }
        },
        "required": [
          "code"
        ]
      }
    }
  }
]

Example tool call syntax:

{
  "tool_calls": [
    {
      "name": "tool_name",
      "arguments": {
        "arg1": "some_value"
      },
      "id": "call_1___"
    }
  ]
}<|im_end|>


<|im_end|>
<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
}
`;

exports[`works fine with vocab_only: empty result 1`] = `
{
  "text": "",
  "timings": {
    "predicted_ms": 0,
    "predicted_n": 1,
    "predicted_per_second": Infinity,
    "predicted_per_token_ms": 0,
    "prompt_ms": 0,
    "prompt_n": 1,
    "prompt_per_second": Infinity,
    "prompt_per_token_ms": 0,
  },
  "tokens_evaluated": 0,
  "tokens_predicted": 0,
  "truncated": false,
}
`;

exports[`works fine with vocab_only: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.file_type": "1",
    "general.name": "LLaMA v2",
    "llama.attention.head_count": "2",
    "llama.attention.head_count_kv": "2",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.block_count": "1",
    "llama.context_length": "4096",
    "llama.embedding_length": "8",
    "llama.feed_forward_length": "32",
    "llama.rope.dimension_count": "4",
    "tokenizer.ggml.bos_token_id": "1",
    "tokenizer.ggml.eos_token_id": "2",
    "tokenizer.ggml.model": "llama",
    "tokenizer.ggml.unknown_token_id": "0",
  },
  "nEmbd": 0,
  "nParams": 513048,
  "size": 1026144,
}
`;

exports[`works fine with vocab_only: tokenize 1`] = `
{
  "tokens": Int32Array [
    9038,
    2501,
    263,
    931,
  ],
}
`;
