// Jest Snapshot v1, https://goo.gl/fbAQLP

exports[`basic completion 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "wallwallwallwallwallwallwallwallwallwall",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 18,
  "tokens_predicted": 9,
  "truncated": false,
}
`;

exports[`basic completion: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "llama ?B Q4_0",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 512,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`completion with response_format: json_object 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{}
		              			",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 12,
  "tokens_predicted": 3,
  "truncated": false,
}
`;

exports[`completion with response_format: json_schema 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "{
 				 				 				 				",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 13,
  "tokens_predicted": 4,
  "truncated": false,
}
`;

exports[`completion with t5-like model 1`] = `
{
  "chat_format": 0,
  "content": "<removed>",
  "context_full": false,
  "interrupted": false,
  "stopped_eos": true,
  "stopped_limited": false,
  "stopped_words": false,
  "stopping_word": "",
  "text": " How old sind er?",
  "timings": "Timings: (8) keys",
  "tokens_evaluated": 17,
  "tokens_predicted": 6,
  "truncated": false,
}
`;

exports[`completion with tools 1`] = `
{
  "additional_stops": [],
  "chat_format": 9,
  "grammar": "any-tool-call ::= ( calc-call ) space
calc-args ::= "{" space  (calc-args-expression-kv )? "}" space
calc-args-expression-kv ::= "\\"expression\\"" space ":" space string
calc-call ::= "{" space calc-call-name-kv "," space calc-call-arguments-kv "}" space
calc-call-arguments ::= "{" space  (calc-call-arguments-expression-kv )? "}" space
calc-call-arguments-expression-kv ::= "\\"expression\\"" space ":" space string
calc-call-arguments-kv ::= "\\"arguments\\"" space ":" space calc-call-arguments
calc-call-name ::= "\\"calc\\"" space
calc-call-name-kv ::= "\\"name\\"" space ":" space calc-call-name
calc-function-tag ::= "<function" ( "=calc" | " name=\\"calc\\"" ) ">" space calc-args "</function>" space
char ::= [^"\\\\\\x7F\\x00-\\x1F] | [\\\\] (["\\\\bfnrt] | "u" [0-9a-fA-F]{4})
root ::= tool-call
space ::= | " " | "\\n"{1,2} [ \\t]{0,20}
string ::= "\\"" char* "\\"" space
tool-call ::= calc-function-tag | wrappable-tool-call | ( "\`\`\`\\n" | "\`\`\`json\\n" | "\`\`\`xml\\n" ) space wrappable-tool-call space "\`\`\`" space 
wrappable-tool-call ::= ( any-tool-call | "<tool_call>" space any-tool-call "</tool_call>" | "<function_call>" space any-tool-call "</function_call>" | "<response>"  space any-tool-call "</response>" | "<tools>"     space any-tool-call "</tools>" | "<json>"      space any-tool-call "</json>" | "<xml>"      space any-tool-call "</xml>" | "<JSON>"      space any-tool-call "</JSON>" ) space
",
  "grammar_triggers": [
    {
      "token": -1,
      "type": 1,
      "value": "<function=calc>",
    },
    {
      "token": -1,
      "type": 2,
      "value": "<function\\s+name\\s*=\\s*"calc"",
    },
    {
      "token": -1,
      "type": 3,
      "value": "(?:<think>[\\s\\S]*?</think>\\s*)?(\\s*(?:<tool_call>|<function|(?:\`\`\`(?:json|xml)?
\\s*)?(?:<function_call>|<tools>|<xml><json>|<response>)?\\s*\\{\\s*"name"\\s*:\\s*"(?:calc)"))[\\s\\S]*",
    },
  ],
  "grammea_lazy": true,
  "has_media": false,
  "media_paths": [],
  "preserved_tokens": [
    "<think>",
    "</think>",
    "<tool_call>",
    "</tool_call>",
    "<function",
    "<tools>",
    "</tools>",
    "<response>",
    "</response>",
    "<function_call>",
    "</function_call>",
    "<json>",
    "</json>",
    "<JSON>",
    "</JSON>",
    "\`\`\`",
    "\`\`\`json",
    "\`\`\`xml",
  ],
  "prompt": "<|im_start|>system
# Tools

You may call one or more functions to assist with the user query.

You are provided with function signatures within <tools></tools> XML tags:
<tools>
{"type": "function", "function": {"name": "calc", "description": "Calculates the result of a math expression.", "parameters": {"type": "object", "properties": {"expression": {"type": "string", "description": "The math expression to evaluate."}}}}}
</tools>

For each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:
<tool_call>
{"name": <function-name>, "arguments": <args-json-object>}
</tool_call><|im_end|>
<|im_start|>user
What is the sum of 1 and 2?<|im_end|>
<|im_start|>assistant
",
  "thinking_forced_open": false,
  "type": "jinja",
}
`;

exports[`loadModelInfo 1`] = `
{
  "alignment": 32,
  "data_offset": 7819680,
  "general.architecture": "llama",
  "general.basename": "Llama-3.2",
  "general.file_type": "2",
  "general.finetune": "1b",
  "general.name": "Llama 3.2 1B",
  "general.organization": "Meta Llama",
  "general.quantization_version": "2",
  "general.size_label": "73M",
  "general.type": "model",
  "llama.attention.head_count": "8",
  "llama.attention.head_count_kv": "2",
  "llama.attention.key_length": "64",
  "llama.attention.layer_norm_rms_epsilon": "0.000010",
  "llama.attention.value_length": "64",
  "llama.block_count": "2",
  "llama.context_length": "131072",
  "llama.embedding_length": "512",
  "llama.feed_forward_length": "2048",
  "llama.rope.dimension_count": "64",
  "llama.rope.freq_base": "500000.000000",
  "llama.vocab_size": "128256",
  "tokenizer.ggml.bos_token_id": "128000",
  "tokenizer.ggml.eos_token_id": "128001",
  "tokenizer.ggml.model": "gpt2",
  "tokenizer.ggml.pre": "llama-bpe",
  "version": 3,
}
`;

exports[`tokeneize & detokenize & getFormattedChat 1`] = `
{
  "bitmap_hashes": [],
  "chunk_pos": [],
  "chunk_pos_media": [],
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;

exports[`tokeneize & detokenize & getFormattedChat 2`] = `"���"`;

exports[`tokeneize & detokenize & getFormattedChat 3`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`tokeneize & detokenize & getFormattedChat 4`] = `
{
  "has_media": false,
  "media_paths": [],
  "prompt": "<|im_start|>user
Hello<|im_end|>
<|im_start|>bot
Hi<|im_end|>
<|im_start|>assistant
",
  "type": "llama-chat",
}
`;

exports[`works fine with vocab_only: empty result 1`] = `
{
  "chat_format": 0,
  "context_full": false,
  "interrupted": false,
  "stopped_eos": false,
  "stopped_limited": true,
  "stopped_words": false,
  "stopping_word": "",
  "text": "",
  "timings": {
    "predicted_ms": 0,
    "predicted_n": 1,
    "predicted_per_second": Infinity,
    "predicted_per_token_ms": 0,
    "prompt_ms": 0,
    "prompt_n": 1,
    "prompt_per_second": Infinity,
    "prompt_per_token_ms": 0,
  },
  "tokens_evaluated": 0,
  "tokens_predicted": 0,
  "truncated": false,
}
`;

exports[`works fine with vocab_only: model info 1`] = `
{
  "chatTemplates": {
    "llamaChat": false,
    "minja": {
      "default": false,
      "defaultCaps": {
        "parallelToolCalls": false,
        "systemRole": true,
        "toolCallId": false,
        "toolCalls": false,
        "toolResponses": false,
        "tools": false,
      },
      "toolUse": false,
    },
  },
  "desc": "",
  "isChatTemplateSupported": false,
  "metadata": {
    "general.architecture": "llama",
    "general.basename": "Llama-3.2",
    "general.file_type": "2",
    "general.finetune": "1b",
    "general.name": "Llama 3.2 1B",
    "general.organization": "Meta Llama",
    "general.quantization_version": "2",
    "general.size_label": "73M",
    "general.type": "model",
    "llama.attention.head_count": "8",
    "llama.attention.head_count_kv": "2",
    "llama.attention.key_length": "64",
    "llama.attention.layer_norm_rms_epsilon": "0.000010",
    "llama.attention.value_length": "64",
    "llama.block_count": "2",
    "llama.context_length": "131072",
    "llama.embedding_length": "512",
    "llama.feed_forward_length": "2048",
    "llama.rope.dimension_count": "64",
    "llama.rope.freq_base": "500000.000000",
    "llama.vocab_size": "128256",
    "tokenizer.ggml.bos_token_id": "128000",
    "tokenizer.ggml.eos_token_id": "128001",
    "tokenizer.ggml.model": "gpt2",
    "tokenizer.ggml.pre": "llama-bpe",
  },
  "nEmbd": 0,
  "nParams": 73271840,
  "size": 58154112,
}
`;

exports[`works fine with vocab_only: tokenize 1`] = `
{
  "bitmap_hashes": [],
  "chunk_pos": [],
  "chunk_pos_media": [],
  "has_media": false,
  "tokens": Int32Array [
    12805,
    5304,
    264,
    892,
  ],
}
`;
